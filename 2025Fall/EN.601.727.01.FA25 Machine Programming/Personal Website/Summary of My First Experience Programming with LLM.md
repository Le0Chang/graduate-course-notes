# Experience and insights from first-time programming with LLM: Building a personal resume website using LLM in the role of "demand leader"
Although the semester has just started and the Machine Programming course hasn't covered programming with LLM yet, I already began trying to use LLM to assist me in programming during my undergraduate studies. The early method was particularly primitive—-I would copy and paste my own bug-filled code into the LLM's chat box and ask it to fix the bugs. However, this was often in vain because bugs always persisted. But this time, I completed the development of my personal resume website entirely through the large language model (Doubao) as a Requirements Proposer rather than a Code Writer. From the initial definition of requirements to the final deployment and launch, I experienced for the first time the core logic of using LLM to handle coding tasks—shifting from manually implementing code to precisely defining requirements, breaking down problems, and iteratively optimizing code. The following are my specific practical experiences:

## Practice Background: The role transition from writing code to defining requirements
The core of the Machine Programming course is to enable LLM to become a collaborative tool for our coding work, and my practical scenario is building a personal resume website. Unlike the traditional programming mode of looking up syntax, typing tags, and repeatedly testing, I did not write a single line of HTML/CSS/JS code throughout the process. Instead, like a project manager, I gradually conveyed specific requirements to the model around the core goal of displaying personal information:

1. Initial requirements: Clearly defining that the website must include three core modules: personal profile (pursuing studies at JHU AMS, focusing on optimization and machine learning), educational experience (undergraduate in the Statistics Experimental Class, master's in AMS), and skills (programming/operating systems/machine learning);

2. Iterative requirements: Putting forward detailed requirements for each part (such as "simplify the About section, retaining only core information", "align the content boxes of B.S. and M.S. to the right in the Experience section", "the timeline axis must pass through the center of the circle", "enhance the card hover effect", etc.);

3. Implementation requirements: Solving problems in the deployment phase (such as "troubleshooting GitHub Pages 404 errors", "repository naming conventions", etc.).

In this mode, I don't need to pay attention to trivial issues such as how to implement timeline animations with Tailwind or how to write responsive layout code. Instead, I can focus on directional issues like what effects I need the website to present and what functions it needs to fulfill. The large language model, on the other hand, takes on the executive role of code implementation, syntax correction, and style adaptation, which aligns well with my current understanding of the concept of the Machine Programming course. It is worth mentioning that the problems encountered during the GitHub deployment steps of this code (such as 404 page errors, abnormal repository configurations, etc.) were also resolved by putting forward troubleshooting requirements to the large language model and obtaining solutions, which further reflects the collaborative value of large language models in the full-process development.

## Core insight: Accurate requirements are the premise for efficient collaboration with large language models.
In practice, I have found that the quality of code output by large language models entirely depends on the clarity and granularity of the requirements I put forward. The pitfalls I encountered initially due to vague requirements have, on the contrary, become the most crucial gains:

1. Commands need to be broken down into executable steps to avoid vague expressions. At first, I only gave the command to beautify the Experience section, and the output effect of the model was rather general, with some redundant content. Later, when I adjusted the commands to specific instructions such as aligning the B.S. and M.S. modules to the right, making the timeline axis pass through the center of the circle, and adding card hover shadow animations, the model was immediately able to accurately meet the visual requirements. This made me realize that in Machine Programming, breaking down requirements is one of the core capabilities. Large language models cannot guess vague requirements; abstract goals must be broken down into quantifiable and describable specific instructions to make the code output meet expectations. Interestingly, the Doubao model provides certain visualization convenience in this aspect—-it allows you to directly put forward modification requirements for the visualized content in the code visualization part, which greatly improves the problem of vague expression of instructions.

2. Commands need to be accompanied by contextual content to reduce misjudgment by the model. For example, when adjusting the education experience module, I initially only said, "Simplify the content," but the model mistakenly deleted key information. Later, I added, "Keep 'JHU AMS Master's' and 'Shandong University Bachelor's (Data Science and AI Experimental Class)', and remove redundant descriptions," and the model executed accurately. This shows that LLM lacks default cognition of personal scenarios. Requirements must include clear contextual boundaries (such as which core information needs to be retained and which redundant content needs to be deleted), especially when involving personal information and professional terms (such as "AMS" and "Optimization and Machine Learning Direction"), which need to be clearly stated to avoid output deviations caused by insufficient information of the model.

3. Commands need to allow iteration and accept the process of gradual optimization. In website development, I went through multiple cycles of requirement adjustment and model modification: for example, first aligning the timeline to the right, then requiring beautification of the circular markers, and finally adding fade-in animations when scrolling. During the deployment phase, from uploading code step by step to troubleshooting 404 errors, it was also carried out through the mode of finding problems and supplementing requirements (such as 'Check if the GitHub repository name conforms to xxx specifications', 'Confirm if GitHub Pages is enabled', etc.). This made me understand that Machine Programming is not about perfectly implementing a requirement in one go, but a closed loop of requirement-output-feedback-optimization. As the leader of requirements, I need to have an iterative thinking—first clarify the core functions, then gradually refine the details. When encountering problems, instead of denying the model, guide the model to correct through supplementary requirements, which is more in line with the actual development logic than putting forward perfect requirements at one time.

## New understanding of the Machine Programming course: Large language models are collaborative tools (employee) and the core role of humans is problem identification and demand control (boss)
This practice has shattered my traditional perception of programming: in the past, I thought that programming meant being able to write code using programming languages, but now I realize that in the context of Machine Programming, it is more important to clearly define what needs to be done, what results need to be achieved, and where problems lie than to be able to write code. Large language models can replace repetitive code writing, but they cannot replace the breakdown of goals, the identification of problems, or the iteration of requirements. For example, when solving the GitHub Pages 404 error, I don't need to understand the principle of DNS resolution, but I need to be able to put forward targeted requirements to the model, such as "check if the repository name is correct" and "confirm if the source branch of GitHub Pages is main". The model will then provide specific solutions based on these requirements. This collaborative model where humans identify the direction of problems and models provide technical solutions is exactly the core of human-machine collaboration emphasized in the Machine Programming course: large language models are tools at the code execution layer, while humans are the leaders at the demand decision-making layer.

## Summary: The essence of Machine Programming is to drive technology implementation through requirements.
This practice of building a website using a large language model has made me deeply understand that Machine Programming is not about having the model replace humans in programming, but about freeing humans from tedious code implementation, allowing them to focus on higher-dimensional demand design and problem-solving. As a self-initiated course practice, it not only honed my ability to express requirements accurately and break down problems, but also made me realize that when facing complex coding tasks in the future, the thinking of clarifying goals, defining boundaries, and iteratively optimizing is of more long-term value than mastering a certain syntax. After all, code can be generated by models, but the core logic of "knowing what to do and how to do it" will always need to be led by humans.
